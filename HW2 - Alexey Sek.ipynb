{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2\n",
    "\n",
    "**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. ML workflow (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные для работы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"winequality-red.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу регрессии: необходимо предсказать качество вина на основе его характеристик\n",
    "\n",
    "### Шаг 1.  (**0.2 балла**)\n",
    "Создайте матрицу X объект-признак и целевой вектор y (\"quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y - последний столбец, X - все остальные\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2. (**0.2 балла**)\n",
    "Разбейте данные на train и test (доля тестовых данных - 30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию train_test_split для этой цели\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3. (**0.2 балла**)\n",
    "Обучите линейную регрессию на тренировочных данных и сделайте предсказания на train и на test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем функцию LinearRegression(), чтобы сделать предсказание\n",
    "\n",
    "lr1 = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "y_pred1_train = lr1.predict(X_train)\n",
    "y_pred1_test = lr1.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4. (**0.4 балла**)\n",
    "Выведите на экран ошибку MSE на train и на test, затем выведите на экран ошибку r2 на train и test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_train: 0.4189162445851497\n",
      "mse_test: 0.41987748164199784\n",
      "r2_train: 0.3748607620409803\n",
      "r2_test: 0.30961311573808714\n"
     ]
    }
   ],
   "source": [
    "# Посчитаем MSE для Train и Test выборок\n",
    "mse_train = mean_squared_error(y_train, y_pred1_train)\n",
    "mse_test = mean_squared_error(y_test, y_pred1_test)\n",
    "\n",
    "# Посчитаем R2 для Train и Test выборо\n",
    "r2_train = r2_score(y_train, y_pred1_train)\n",
    "r2_test = r2_score(y_test, y_pred1_test)\n",
    "\n",
    "# Выведем полученные значения\n",
    "print('mse_train:', mse_train)\n",
    "print('mse_test:', mse_test)\n",
    "\n",
    "print('r2_train:', r2_train)\n",
    "print('r2_test:', r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5. (**0.5 балла**)\n",
    "Вычислите среднее качество (r2) модели на кросс-валидации с k=5 фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_r2_cv: 0.2900416288421967\n"
     ]
    }
   ],
   "source": [
    "# Используем r2 как score, который подсчитывается на кросс валидации\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "num_splits=5\n",
    "\n",
    "cv_res = cross_validate(lr1, X, y, scoring='r2', cv=num_splits)\n",
    "\n",
    "print('mean_r2_cv:', np.mean(cv_res['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6.  (**0.5 балла**)\n",
    "Теперь примените линейную регрессию с L1-регуляризацией (Lasso) для данной задачи. Объявите модель и подберите параметр регуляризации alpha по сетке. Ищите alpha в диапазоне (0.1, 1.1) с шагом 0.1. \n",
    "\n",
    "Осуществите подбор параметра alpha по тренировочным данным (Xtrain, ytrain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "# Используем кроссвалидацию, чтобы найти оптимальный гипермпараметр alpha регуляризации\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "lasso = Lasso()\n",
    "num_splits = 5\n",
    "alphas = np.linspace(0.1,1.1,11)\n",
    "params = {'alpha':alphas}\n",
    "\n",
    "cv = GridSearchCV(lasso, params, scoring='r2', cv=num_splits)\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "# Это и есть наш оптимальный гиперпараметр\n",
    "print(cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7.  (**0.5 балла**)\n",
    "Выведите наилучший алгоритм и наилучшее качество по результатам подбора alpha (best_estimator_ и best_score_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_estimator: Lasso(alpha=0.1)\n",
      "best_score: 0.2533626619326174\n"
     ]
    }
   ],
   "source": [
    "# Используем оптимальный альфа из прошлого пункта, чтобы посчитать лучший r2 на тренировочных данных, который мы можем получить в LASSO модели\n",
    "print('best_estimator:', cv.best_estimator_)\n",
    "print('best_score:', cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 8.  (**0.5 балла**)\n",
    "\n",
    "С помощью найденного best_estimator_ сделайте предсказание на тестовых данных и выведите на экран r2-score на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_test: 0.2106617839974564\n"
     ]
    }
   ],
   "source": [
    "# Используя best estimator вывели r2 на тесте\n",
    "best_est = cv.best_estimator_\n",
    "y_pred = best_est.predict(X_test)\n",
    "\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "print('r2_test:', r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 9.  (**0.5 балла**)\n",
    "\n",
    "Попробуем улучшить качество модели за счет добавления полиномиальных признаков. Создайте pipeline, состоящий из добавления полиномиальных признаков степени 2, а затем применения линейной регрессии.\n",
    "\n",
    "Затем вычислите r2-score этой модели на кросс валидации с пятью фолдами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим полиномиальные признаки в модель, используем pipeline для этого\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#your code here\n",
    "pipe = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model_', LinearRegression())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 pipe: 0.23009616556632376\n"
     ]
    }
   ],
   "source": [
    "cv_res = cross_validate(pipe, X, y, scoring='r2', cv=5)\n",
    "print('r2 pipe:', np.mean(cv_res['test_score']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 10.  (**0.5 балла**)\n",
    "Обучите модель (pipeline) на тренировочных данных и сделайте предсказания для train и test, затем выведите на экран r2-score и MSE на тренировочных и на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используя pipeline обучим регрессию и сделаем прогноз\n",
    "pipe.fit(X_train, y_train)\n",
    "y_pipe_pred_train = pipe.predict(X_train)\n",
    "y_pipe_pred_test = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_train: 0.3622378456375558\n",
      "mse_test: 0.4412735881742095\n",
      "r2_train: 0.459440655002458\n",
      "r2_test: 0.2744323976239771\n"
     ]
    }
   ],
   "source": [
    "mse_train = mean_squared_error(y_train, y_pipe_pred_train)\n",
    "mse_test = mean_squared_error(y_test, y_pipe_pred_test)\n",
    "\n",
    "r2_train = r2_score(y_train, y_pipe_pred_train)\n",
    "r2_test = r2_score(y_test, y_pipe_pred_test)\n",
    "\n",
    "print('mse_train:', mse_train)\n",
    "print('mse_test:', mse_test)\n",
    "\n",
    "print('r2_train:', r2_train)\n",
    "print('r2_test:', r2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сделайте выводы. Для этого ответьте на вопросы: (**1 балл**)\n",
    "\n",
    "1) Хорошее ли качество показала исходная модель (линейная регрессия без регуляризации)? Является ли эта модель переобученной?\n",
    "\n",
    "2) Помогла ли L1-регуляризация улучшить качество модели?\n",
    "\n",
    "3) Помогло ли добавление полиномов второй степени улучшить качество модели? Как добавление новых признаков повлияло на переобучение?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "1. MSE ~ 0.45, R^2 ~ 0.32 на тестовых данных не кажется мне хорошим качеством. При этом мы видим, что MSE на train ниже, а R2 на train выше, что указывает на то, что модель дает лучшие результаты на тренировочных данных. Вероятно, здесь мы наблюдаем переобучение\n",
    "2. Если мой код верный, то R^2 только уменьшился после введения L1-регуляризация, поэтому нет, качество модели не удалось улучшить\n",
    "3. Добавление полиномов второй степени только ухудшило модель - переобучение стало еще более явным, потому что модель лучше \"подогналась\" под тренировочные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Попытайтесь улучшить модель (добейтесь наилучшего качества) - можно использовать любые методы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При улучшении качества r2 на 0.1-0.2 +1 балл, при большем улучшении +2 балла (дополнительно к 5 баллам за основную часть)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Не получилось\n",
    "Я пробовал Elastic net и Random Forest с кроссвалидацией для поиска оптимальных гиперпараметров, но это не помогло улучшить качество"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Target encoding (**всего 5 баллов**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом части домашнего задания вы будете работать с выборкой `1C`. Вам нужно посчитать счетчики для `item_id` четырьмя способами:\n",
    "\n",
    "    1) При помощи KFold схемы;  \n",
    "    2) При помощи Leave-one-out схемы;\n",
    "    3) При помощи smoothing схемы;\n",
    "    4) При помощи expanding mean схемы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_price</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>22154</td>\n",
       "      <td>999.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>05.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2552</td>\n",
       "      <td>899.00</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>06.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2554</td>\n",
       "      <td>1709.05</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.01.2013</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2555</td>\n",
       "      <td>1099.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935844</th>\n",
       "      <td>10.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7409</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935845</th>\n",
       "      <td>09.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935846</th>\n",
       "      <td>14.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7459</td>\n",
       "      <td>349.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935847</th>\n",
       "      <td>22.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7440</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2935848</th>\n",
       "      <td>03.10.2015</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>7460</td>\n",
       "      <td>299.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2935849 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               date  date_block_num  shop_id  item_id  item_price  target\n",
       "0        02.01.2013               0       59    22154      999.00     1.0\n",
       "1        03.01.2013               0       25     2552      899.00     1.0\n",
       "2        05.01.2013               0       25     2552      899.00    -1.0\n",
       "3        06.01.2013               0       25     2554     1709.05     1.0\n",
       "4        15.01.2013               0       25     2555     1099.00     1.0\n",
       "...             ...             ...      ...      ...         ...     ...\n",
       "2935844  10.10.2015              33       25     7409      299.00     1.0\n",
       "2935845  09.10.2015              33       25     7460      299.00     1.0\n",
       "2935846  14.10.2015              33       25     7459      349.00     1.0\n",
       "2935847  22.10.2015              33       25     7440      299.00     1.0\n",
       "2935848  03.10.2015              33       25     7460      299.00     1.0\n",
       "\n",
       "[2935849 rows x 6 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales = pd.read_csv('sales_train.csv.gz')\n",
    "sales.columns = ['date', 'date_block_num', 'shop_id', 'item_id', 'item_price', 'target']\n",
    "sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in sales['date_block_num'].unique():\n",
    "    cur_shops = sales[sales['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales[sales['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols,dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales.groupby(index_cols,as_index=False).agg({'target':'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid,gb,how='left',on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num','shop_id','item_id'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean encodings без регуляризации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После проделанной технической работы, мы готовы посчитать счетчики для переменной `item_id`. \n",
    "\n",
    "Ниже приведены две реализации подсчета счетчиков без регуляризации. Можно использовать данный код в качестве стартовой точки для реализации различных техник регуляризации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621699\n"
     ]
    }
   ],
   "source": [
    "# Calculate a mapping: {item_id: target_mean}\n",
    "item_id_target_mean = all_data.groupby('item_id').target.mean()\n",
    "\n",
    "# In our non-regularized case we just *map* the computed means to the `item_id`'s\n",
    "all_data['item_target_enc'] = all_data['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Способ 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4830386988621699\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "     Differently to `.target.mean()` function `transform` \n",
    "   will return a dataframe with an index like in `all_data`.\n",
    "   Basically this single line of code is equivalent to the first two lines from of Method 1.\n",
    "'''\n",
    "all_data['item_target_enc'] = all_data.groupby('item_id')['target'].transform('mean')\n",
    "\n",
    "# Fill NaNs\n",
    "all_data['item_target_enc'].fillna(0.3343, inplace=True) \n",
    "\n",
    "# Print correlation\n",
    "encoded_feature = all_data['item_target_enc'].values\n",
    "print(np.corrcoef(all_data['target'].values, encoded_feature)[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KFold схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать Kfold схему с пятью фолдами. Используйте KFold(5) из sklearn.model_selection. \n",
    "\n",
    "1. Разбейте данные на 5 фолдов при помощи `sklearn.model_selection.KFold` с параметром `shuffle=False`.\n",
    "2. Проитерируйтесь по фолдам: используйте 4 обучающих фолда для подсчета средних значений таргета по `item_id` и заполните этими значениями валидационный фолд на каждой итерации.\n",
    "\n",
    "Обратите внимание на **Способ 1** из примера. В частности, изучите, как работают функции map и pd.Series.map. Они довольно полезны во многих ситуациях. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4164590712798811\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Давайте создадим еще один столбец и заполним его нулями\n",
    "all_data['K_fold_scheme'] = np.zeros\n",
    "kf = KFold(n_splits=5, shuffle=False)\n",
    "\n",
    "# Проитерируемся по фолдам и подсчитаем средние значения таргета по item_id, заполним ими новый столбец\n",
    "for train_index, validation_index in kf.split(all_data):\n",
    "    \n",
    "    all_data_train, all_data_validation = all_data.iloc[train_index], all_data.iloc[validation_index]\n",
    "    item_id_target_mean = all_data_train.groupby('item_id').target.mean()\n",
    "    all_data.loc[all_data.index[validation_index], 'K_fold_scheme'] = all_data_validation['item_id'].map(item_id_target_mean)\n",
    "\n",
    "# Заполним NaN values 0.3343 (из условия - было в прошлых пунктах способ 1, способ 2)\n",
    "all_data['K_fold_scheme'] = all_data['K_fold_scheme'].fillna(0.3343)\n",
    "\n",
    "encoded_feature = all_data['K_fold_scheme'].values\n",
    "    \n",
    "# You will need to compute correlation like that\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4165"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать leave-one-out схему . Учтите, если вы запустите код из первого задания, задав количество фолдов такое же как размер выборки, то вы, вероятно, получите правильный ответ, но ждать будете очень-очень долго.\n",
    "\n",
    "Для более быстрой реализации подсчета среднего таргета на всех объектах, кроме одного, вы можете:\n",
    "\n",
    "1. Вычислить суммарный таргет по всем объектам.\n",
    "2. Вычесть таргет конкретного объекта и разделить результат на `n_objects - 1`. \n",
    "\n",
    "Заметим, что пункт `1.` следует сделать для всех объектов. Также заметим, что пункт `2.` может быть реализован без циклов `for`.\n",
    "\n",
    "Здесь может оказаться полезной функция .transform из **Способа 2** из примера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4803848311293002\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "\n",
    "# Вычислили суммарный таргет по всем объектам\n",
    "# Вычислим количество объектов\n",
    "count_LOO = all_data['item_id'].map(all_data.groupby('item_id').target.count())\n",
    "sum_LOO = all_data['item_id'].map(all_data.groupby('item_id').target.sum())\n",
    "\n",
    "# Делить надо именно на количество объектов минус 1\n",
    "all_data['LOO'] = ((sum_LOO - all_data['target']))/(count_LOO-1)\n",
    "all_data['LOO'] = all_data['LOO'].fillna(0.3343)\n",
    "\n",
    "encoded_feature = all_data['LOO'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать smoothing с $\\alpha = 100$. Используйте формулу:\n",
    "\n",
    "$\\frac{mean(target) \\cdot nrows + globalmean \\cdot \\alpha }{nrows + \\alpha}$,\n",
    "\n",
    "где $globalmean=0.3343$. Заметим, что `nrows` - это количество объектов, принадлежащих конктертной категории, а не количество строк в датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4818198797097264\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "alpha = 100\n",
    "globalmean = 0.3343\n",
    "\n",
    "# Как указано в условии нам нужно именно таким образом посчитать nrows\n",
    "nrows = all_data.groupby('item_id').size()\n",
    "mean = all_data.groupby('item_id')['target'].agg('mean')\n",
    "\n",
    "# Используем формулу из условия\n",
    "score = ((mean * nrows)  + globalmean * alpha) / (nrows + alpha)\n",
    "\n",
    "# Добавим столбец со сглаживанием\n",
    "all_data['smoothing'] = all_data['item_id']\n",
    "all_data['smoothing'] = all_data['smoothing'].map(score)\n",
    "\n",
    "encoded_feature = all_data['smoothing'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.4818"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding mean схема (**1.25 балла**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимо реализовать *expanding mean* схему. Ее суть заключается в том, чтобы пройти по отсортированному в определенном порядке датасету (датасет сортируется в самом начале задания) и для подсчета счетчика для строки $m$ использовать строки от $0$ до $m-1$. Вам будет необходимо воспользоваться pandas функциями [`cumsum`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.DataFrameGroupBy.cumsum.html) и [`cumcount`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.groupby.GroupBy.cumcount.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5025245211081697\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# Используем функции cumsum и cumcoun для предварительных расчетов\n",
    "cumcount = all_data.groupby('item_id').cumcount()\n",
    "cumsum = all_data.groupby('item_id').target.cumsum() - all_data['target']\n",
    "\n",
    "# Посчитаем нужные нам значения\n",
    "exp_mean = cumsum/cumcount\n",
    "\n",
    "# Вставим полученные значения в новый столбец датасета и заполним пропуски\n",
    "all_data['exp_mean'] = exp_mean\n",
    "all_data['exp_mean'] = all_data['exp_mean'].fillna(0.3343) \n",
    "\n",
    "encoded_feature = all_data['exp_mean'].values\n",
    "\n",
    "corr = np.corrcoef(all_data['target'].values, encoded_feature)[0][1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидаемый ответ 0.5025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
